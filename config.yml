recipe: default.v1
language: en
pipeline:
- name: CompactLLMCommandGenerator
  llm:
    model_group: gpt4o
  prompt_template: prompts/gpt4o.jinja2  # use for gpt4o, sonnet-3.5

policies:
- name: FlowPolicy
# - name: EnterpriseSearchPolicy
#   vector_store:
#     type: "components.kapa.Kapa"

# - name: rasa_plus.ml.EnterpriseSearchPolicy
  # docker run -p 6333:6333 -p 6334:6334 -v $(pwd)/local_data:/qdrant/storage:z qdrant/qdrant
  # vector_store:
  #   type: "qdrant"
    # Fails
    # type: "huggingface_hub"
    # repo_id: "mistralai/Mistral-7B-Instruct-v0.1"

# {"status":{"error":"Wrong input: Vector inserting error: expected dim: 384, got 1536"},"time":0.001769584}
# privateGPT settings
  # llm:
  #   type: "huggingface_hub"
  #   repo_id: BAAI/bge-small-en-v1.5
    # repo_id: "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
    # model_file: mistral-7b-instruct-v0.1.Q4_K_M.gguf

# privateGPT settings
# local:
#   llm_hf_repo_id: ${PGPT_HF_REPO_ID:TheBloke/Mistral-7B-Instruct-v0.1-GGUF}
#   llm_hf_model_file: ${PGPT_HF_MODEL_FILE:mistral-7b-instruct-v0.1.Q4_K_M.gguf}
#   embedding_hf_model_name: ${PGPT_EMBEDDING_HF_MODEL_NAME:BAAI/bge-small-en-v1.5}

  # embeddings:
  #   type: openai
  #   model: text-embedding-ada-002
  #   deployment: embeddings
  # embeddings:
  #   type: "llamacpp"
  #   model_path: "/Users/greg/Dev/llm/privateGPT/mistral-7b-instruct-v0.1.Q4_K_M.gguf"
    # type: "huggingface_hub"
    # repo_id: "BAAI/bge-small-en-v1.5"
    # repo_id: "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
    # model_file: mistral-7b-instruct-v0.1.Q4_K_M.gguf

  # llm:
  #   type: "llamacpp"
  #   model_path: "/Users/greg/Dev/llm/privateGPT/mistral-7b-instruct-v0.1.Q4_K_M.gguf"

  # llm:
  #   type: openai
  #   model_name: gpt-4
assistant_id: 20250413-080459-recent-bilge
